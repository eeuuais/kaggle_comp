# Kaggle competition review

## Binary classification : Tabular data
**1. Titanic: Machine Learning from Disaster**
- (1-1) 1 - Exploratory data analysis, visualization, machine learning
	- 중점 내용
  
- (1-2) EDA To Prediction(DieTanic)
	- 중점 내용
- (1-3) Titanic Top 4% with ensemble modeling
	- 중점 내용
- (1-4) Introduction to Ensembling/Stacking in Python
	- 중점 내용
  - issue : sklearn 명령어가 변경되어 오류 해결
  
  **2. Porto Seguro’s Safe Driver Prediction **
- (2-1) Data Preparation & Exploration
- (2-2) Interactive Porto Insights - A Plot.ly Tutorial
- (2-3) XGBoost CV (LB .284)
- (2-4) Porto Seguro Exploratory Analysis and Prediction


**3. Home Credit Default Risk **
- Introduction: Home Credit Default Risk Competition
- Introduction to Manual Feature Engineering
- Stacking Test-Sklearn, XGBoost, CatBoost, LightGBM
- LightGBM 7th place solution

## Multi-class classification : Tabular data
**1. Costa Rican Household Poverty Level Prediction**
- A Complete Introduction and Walkthrough
- 3250feats->532 feats using shap[LB: 0.436]
- XGBoost

## Binary classification : Image classification
**1. Statoil/C-CORE Iceberg Classifier Challenge**
- Keras Model for Beginners (0.210 on LB)+EDA+R&D
- Transfer Learning with VGG-16 CNN+AUG LB 0.1712
- Submarineering.EVEN BETTER PUBLIC SCORE until now.
- Keras+TF LB 0.18
